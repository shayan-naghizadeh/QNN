{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622dd8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, torch, torch.nn as nn, torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de36e18",
   "metadata": {},
   "source": [
    "**parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3cfc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in, num_hid, num_out = 784, 256, 10\n",
    "beta, T, bs, epochs, lr = 1, 50, 128, 3, 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38397089",
   "metadata": {},
   "source": [
    "**device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554678c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f2fca6fc90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874dbaa8",
   "metadata": {},
   "source": [
    "**arch network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f2d2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1  = nn.Linear(num_in , num_hid, bias=False)\n",
    "        self.lif1 = snn.Leaky(beta=beta,threshold=0.8)\n",
    "        self.fc2  = nn.Linear(num_hid, num_out, bias=False)\n",
    "        self.lif2 = snn.Leaky(beta=beta,threshold=0.8)\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.fc1.weight.dtype)\n",
    "        mem1 = self.lif1.init_leaky().to(device=x.device, dtype=x.dtype)\n",
    "        mem2 = self.lif2.init_leaky().to(device=x.device, dtype=x.dtype)\n",
    "        out  = []\n",
    "        for t in range(x.size(0)):\n",
    "            spk1, mem1 = self.lif1(self.fc1(x[t]), mem1)\n",
    "            spk1 = spk1.to(dtype=self.fc2.weight.dtype)        #\n",
    "            spk2, mem2 = self.lif2(self.fc2(spk1), mem2)\n",
    "            out.append(spk2)\n",
    "        return torch.stack(out)                                # [T,B,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdd6624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.Compose([transforms.ToTensor()])\n",
    "train_ds = torchvision.datasets.MNIST(\"data\", True , download=True, transform=tr)\n",
    "test_ds  = torchvision.datasets.MNIST(\"data\", False, download=True, transform=tr)\n",
    "train_ld = DataLoader(train_ds, bs, True , num_workers=2, pin_memory=True)\n",
    "test_ld  = DataLoader(test_ds , bs, False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff8cf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SNN().to(device)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa76cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de613b",
   "metadata": {},
   "source": [
    "**train phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0468a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_ld,epochs):\n",
    "    for ep in range(1, epochs + 1):\n",
    "        net.train()\n",
    "        for imgs, lbls in tqdm(train_ld, desc=f\"train {ep}/{epochs}\"):\n",
    "            imgs = imgs.to(device).view(imgs.size(0), -1) \n",
    "            lbls = lbls.to(device)\n",
    "            spk  = spikegen.rate(imgs, T).to(device)\n",
    "            loss = loss_fn(net(spk).sum(0), lbls)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb0376ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 1/3: 100%|██████████| 469/469 [03:28<00:00,  2.25it/s]\n",
      "train 2/3: 100%|██████████| 469/469 [02:45<00:00,  2.84it/s]\n",
      "train 3/3: 100%|██████████| 469/469 [01:55<00:00,  4.06it/s]\n"
     ]
    }
   ],
   "source": [
    "train(net,train_ld,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae666a1",
   "metadata": {},
   "source": [
    "**test phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f888115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,loader):\n",
    "    @torch.no_grad()\n",
    "    def evaluate(model, loader, dtype):\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = (imgs.to(device).view(imgs.size(0), -1) ).to(dtype)\n",
    "            spk  = spikegen.rate(imgs, T).to(dtype).to(device)\n",
    "            preds = model(spk).sum(0).argmax(1)\n",
    "            correct += (preds == lbls.to(device)).sum().item()\n",
    "            total   += lbls.size(0)\n",
    "        return 100 * correct / total\n",
    "\n",
    "\n",
    "    acc32 = evaluate(net, test_ld, torch.float32)\n",
    "\n",
    "\n",
    "    net_fp16 = SNN().to(device)\n",
    "    net_fp16.load_state_dict(net.state_dict())\n",
    "    net_fp16.half().eval()\n",
    "    acc16 = evaluate(net_fp16, test_ld, torch.float16)\n",
    "\n",
    "    print(f\"Accuracy FP32 : {acc32:.2f}%\")\n",
    "    print(f\"Accuracy FP16 : {acc16:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97f596",
   "metadata": {},
   "source": [
    "create a test data spike train for cpp program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bdb7097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n",
      "Spike array shape: torch.Size([50, 784])\n",
      "Spike array (as int):\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "imgs, lbls = next(iter(test_ld))\n",
    "\n",
    "img = imgs[1].to(device)\n",
    "label = lbls[1].item()\n",
    "\n",
    "img_flat = img.view(-1)\n",
    "\n",
    "\n",
    "spk = spikegen.rate(img_flat.unsqueeze(0), T).squeeze(1) \n",
    "\n",
    "print(\"Label:\", label)\n",
    "print(\"Spike array shape:\", spk.shape)  # [T, 784]\n",
    "print(\"Spike array (as int):\")\n",
    "print(spk.int())\n",
    "\n",
    "spk_t = spk.int().cpu().tolist()  \n",
    "\n",
    "with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\HW\\\\FP32\\\\spikes.cpp\", \"w\") as f:\n",
    "    f.write(\"#include <vector>\\n\")\n",
    "    f.write(\"#include \\\"spikes.h\\\"\\n\")\n",
    "    f.write(f\"int label = {label};\\n\")\n",
    "    f.write(\"std::vector<std::vector<int>> spike_input = {\\n\")\n",
    "    \n",
    "    for i, row in enumerate(spk_t): \n",
    "        row_str = \", \".join(str(x) for x in row)\n",
    "        comma = \",\" if i < len(spk_t) - 1 else \"\"\n",
    "        f.write(f\"    {{{row_str}}}{comma}\\n\")\n",
    "    f.write(\"};\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bcb16",
   "metadata": {},
   "source": [
    "create dataset for test with cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "416e0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = 1000  \n",
    "\n",
    "# all_spikes = []\n",
    "# all_labels = []\n",
    "\n",
    "# for batch_imgs, batch_lbls in test_ld:\n",
    "#     for i in range(len(batch_imgs)):\n",
    "#         if len(all_labels) >= num_samples:\n",
    "#             break\n",
    "\n",
    "#         img = batch_imgs[i].to(device)\n",
    "#         label = batch_lbls[i].item()\n",
    "#         img_flat = img.view(-1)\n",
    "\n",
    "#         spk = spikegen.rate(img_flat.unsqueeze(0), T).squeeze(1)  \n",
    "#         spk_np = spk.int().cpu().tolist()  \n",
    "\n",
    "#         all_spikes.append(spk_np)         \n",
    "#         all_labels.append(label)          \n",
    "\n",
    "#     if len(all_labels) >= num_samples:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6c55fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#     # with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\QNN\\\\HW\\\\FP32\\\\TestDataset.cpp\", \"w\") as f:\n",
    "# #     f.write(\"#include <vector>\\n\")\n",
    "# #     f.write(\"#include \\\"TestDataset.h\\\"\\n\")\n",
    "# #     f.write(\"std::vector<int> labels = {\\n\")\n",
    "# #     f.write(\"    \" + \", \".join(str(lbl) for lbl in all_labels) + \"\\n};\\n\\n\")\n",
    "\n",
    "# #     f.write(\"std::vector<std::vector<std::vector<int>>> dataset_spikes = {\\n\")\n",
    "# #     for i, sample in enumerate(all_spikes):\n",
    "# #         f.write(\"    {\\n\")\n",
    "# #         for j, timestep in enumerate(sample):\n",
    "# #             row_str = \", \".join(str(x) for x in timestep)\n",
    "# #             comma = \",\" if j < len(sample) - 1 else \"\"\n",
    "# #             f.write(f\"        {{{row_str}}}{comma}\\n\")\n",
    "# #         comma_sample = \",\" if i < len(all_spikes) - 1 else \"\"\n",
    "# #         f.write(f\"    }}{comma_sample}\\n\")\n",
    "# #     f.write(\"};\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362fbda",
   "metadata": {},
   "source": [
    "datatest with txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbbaafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "T = 50\n",
    "num_samples = 10000\n",
    "\n",
    "label_file = open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\hls\\\\labels.txt\", \"w\")\n",
    "spike_file = open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\hls\\\\spikes.txt\", \"w\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for batch_imgs, batch_lbls in test_ld:\n",
    "        for i in range(len(batch_imgs)):\n",
    "            if count >= num_samples:\n",
    "                break\n",
    "\n",
    "            img = batch_imgs[i].to(device)\n",
    "            label = batch_lbls[i].item()\n",
    "\n",
    "            img_flat = img.view(-1).unsqueeze(0)                 # [1, 784]\n",
    "            spk = spikegen.rate(img_flat, T)                     # [T, 1, 784]\n",
    "            spk = spk.squeeze(1).int().cpu()                     # [T, 784]\n",
    "\n",
    "            if spk.shape != (T, 784):\n",
    "                raise ValueError(f\"Expected shape [50, 784], got {spk.shape}\")\n",
    "\n",
    "            spike_file.write(f\"# sample {count}\\n\")\n",
    "            for timestep in spk:\n",
    "                line = \" \".join(str(bit.item()) for bit in timestep)\n",
    "                spike_file.write(line + \"\\n\")\n",
    "\n",
    "            label_file.write(f\"{label}\\n\")\n",
    "            count += 1\n",
    "\n",
    "        if count >= num_samples:\n",
    "            break\n",
    "\n",
    "spike_file.close()\n",
    "label_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b540b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('model_weights.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "873a3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy FP32 : 96.07%\n",
      "Accuracy FP16 : 96.15%\n"
     ]
    }
   ],
   "source": [
    "test(net,test_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d755096",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dca06a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_fp16 = SNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eee71c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_fp16.load_state_dict(net.state_dict())\n",
    "\n",
    "net_fp16 = net_fp16.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "037ea01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.010213527828454971313476562500,  0.034269195050001144409179687500,\n",
       "          0.032603953033685684204101562500,  ...,\n",
       "          0.014157786965370178222656250000, -0.016394995152950286865234375000,\n",
       "         -0.006290988996624946594238281250],\n",
       "        [-0.035448536276817321777343750000, -0.005012039095163345336914062500,\n",
       "         -0.024140700697898864746093750000,  ...,\n",
       "          0.029441650956869125366210937500,  0.019238635897636413574218750000,\n",
       "         -0.001913335174322128295898437500],\n",
       "        [-0.030705563724040985107421875000,  0.005754742771387100219726562500,\n",
       "          0.031043078750371932983398437500,  ...,\n",
       "          0.020431201905012130737304687500, -0.004949940368533134460449218750,\n",
       "         -0.016702154651284217834472656250],\n",
       "        ...,\n",
       "        [-0.023359090089797973632812500000,  0.009700365364551544189453125000,\n",
       "          0.030937489122152328491210937500,  ...,\n",
       "          0.014517899602651596069335937500,  0.028145592659711837768554687500,\n",
       "         -0.033120647072792053222656250000],\n",
       "        [-0.024598229676485061645507812500, -0.008918927982449531555175781250,\n",
       "          0.011767894029617309570312500000,  ...,\n",
       "          0.034619163721799850463867187500,  0.016593977808952331542968750000,\n",
       "          0.005625285208225250244140625000],\n",
       "        [-0.022782927379012107849121093750,  0.022081535309553146362304687500,\n",
       "          0.030176308006048202514648437500,  ...,\n",
       "          0.028846342116594314575195312500, -0.006643155589699745178222656250,\n",
       "         -0.033929925411939620971679687500]], requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1563e3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.010215759277343750000000000000,  0.034271240234375000000000000000,\n",
       "          0.032592773437500000000000000000,  ...,\n",
       "          0.014160156250000000000000000000, -0.016387939453125000000000000000,\n",
       "         -0.006290435791015625000000000000],\n",
       "        [-0.035461425781250000000000000000, -0.005012512207031250000000000000,\n",
       "         -0.024139404296875000000000000000,  ...,\n",
       "          0.029434204101562500000000000000,  0.019241333007812500000000000000,\n",
       "         -0.001913070678710937500000000000],\n",
       "        [-0.030700683593750000000000000000,  0.005756378173828125000000000000,\n",
       "          0.031036376953125000000000000000,  ...,\n",
       "          0.020431518554687500000000000000, -0.004951477050781250000000000000,\n",
       "         -0.016708374023437500000000000000],\n",
       "        ...,\n",
       "        [-0.023361206054687500000000000000,  0.009696960449218750000000000000,\n",
       "          0.030944824218750000000000000000,  ...,\n",
       "          0.014518737792968750000000000000,  0.028152465820312500000000000000,\n",
       "         -0.033111572265625000000000000000],\n",
       "        [-0.024597167968750000000000000000, -0.008918762207031250000000000000,\n",
       "          0.011764526367187500000000000000,  ...,\n",
       "          0.034606933593750000000000000000,  0.016601562500000000000000000000,\n",
       "          0.005626678466796875000000000000],\n",
       "        [-0.022781372070312500000000000000,  0.022079467773437500000000000000,\n",
       "          0.030181884765625000000000000000,  ...,\n",
       "          0.028839111328125000000000000000, -0.006641387939453125000000000000,\n",
       "         -0.033935546875000000000000000000]], dtype=torch.float16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_fp16.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(),'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444277c7",
   "metadata": {},
   "source": [
    "Write weights with format cpp in weights.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0880f",
   "metadata": {},
   "source": [
    "with 6 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0361a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.eval()\n",
    "# with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\HW\\\\FP32\\\\weightst.cpp\", \"w\") as cpp_file:\n",
    "#     cpp_file.write(\"#include <vector>\\n\\n\")\n",
    "#     cpp_file.write(\"#include \\\"weights.h\\\"\\n\\n\")\n",
    "\n",
    "#     for name, param in net.state_dict().items():\n",
    "#         cpp_name = name.replace(\".\", \"_\")\n",
    "#         data = param.cpu().numpy()\n",
    "#         shape = data.shape\n",
    "\n",
    "#         if \"weight\" in name and len(shape) == 2:\n",
    "#             data = data.T  # Transpose to [input][output]\n",
    "#             shape = data.shape\n",
    "\n",
    "#             cpp_file.write(f\"// shape: {shape} // Transposed\\n\")\n",
    "#             cpp_file.write(f\"std::vector<std::vector<float>> {cpp_name} = {{\\n\")\n",
    "\n",
    "#             for row in data:\n",
    "#                 row_str = \", \".join(f\"{v:.6f}\" for v in row)\n",
    "#                 cpp_file.write(f\"    {{{row_str}}},\\n\")\n",
    "\n",
    "#             cpp_file.write(\"};\\n\\n\")\n",
    "\n",
    "#         elif \"bias\" in name and len(shape) == 1:\n",
    "#             cpp_file.write(f\"// shape: {shape}\\n\")\n",
    "#             cpp_file.write(f\"std::vector<float> {cpp_name} = {{\\n    \")\n",
    "#             cpp_file.write(\", \".join(f\"{v:.6f}\" for v in data))\n",
    "#             cpp_file.write(\"\\n};\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0261ac8",
   "metadata": {},
   "source": [
    "with 25 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c47744be",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\HW\\\\FP32\\\\weights_.cpp\", \"w\") as cpp_file:\n",
    "    cpp_file.write(\"#include <vector>\\n\\n\")\n",
    "    cpp_file.write(\"#include \\\"weights.h\\\"\\n\\n\")\n",
    "\n",
    "    for name, param in net.state_dict().items():\n",
    "        cpp_name = name.replace(\".\", \"_\")\n",
    "        data = param.cpu().numpy()\n",
    "        shape = data.shape\n",
    "\n",
    "        if \"weight\" in name and len(shape) == 2:\n",
    "            data = data.T  # Transpose to [input][output]\n",
    "            shape = data.shape\n",
    "\n",
    "            cpp_file.write(f\"// shape: {shape} // Transposed\\n\")\n",
    "            cpp_file.write(f\"const std::vector<std::vector<float>> {cpp_name} = {{\\n\")\n",
    "\n",
    "            for row in data:\n",
    "                row_str = \", \".join(f\"{v:.25f}\" for v in row)  \n",
    "                cpp_file.write(f\"    {{{row_str}}},\\n\")\n",
    "\n",
    "            cpp_file.write(\"};\\n\\n\")\n",
    "\n",
    "        elif \"bias\" in name and len(shape) == 1:\n",
    "            cpp_file.write(f\"// shape: {shape}\\n\")\n",
    "            cpp_file.write(f\"const std::vector<float> {cpp_name} = {{\\n    \")\n",
    "            cpp_file.write(\", \".join(f\"{v:.25f}\" for v in data)) \n",
    "            cpp_file.write(\"\\n};\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "725d4f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.800000011920928955078125000000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.lif1.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc94a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
