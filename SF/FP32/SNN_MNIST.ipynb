{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622dd8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, torch, torch.nn as nn, torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de36e18",
   "metadata": {},
   "source": [
    "**parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3cfc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in, num_hid, num_out = 784, 256, 10\n",
    "beta, T, bs, epochs, lr = 0.9, 50, 128, 3, 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38397089",
   "metadata": {},
   "source": [
    "**device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554678c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x294aadcfc90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874dbaa8",
   "metadata": {},
   "source": [
    "**arch network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2d2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1  = nn.Linear(num_in , num_hid, bias=False)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2  = nn.Linear(num_hid, num_out, bias=False)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.fc1.weight.dtype)\n",
    "        mem1 = self.lif1.init_leaky().to(device=x.device, dtype=x.dtype)\n",
    "        mem2 = self.lif2.init_leaky().to(device=x.device, dtype=x.dtype)\n",
    "        out  = []\n",
    "        for t in range(x.size(0)):\n",
    "            spk1, mem1 = self.lif1(self.fc1(x[t]), mem1)\n",
    "            spk1 = spk1.to(dtype=self.fc2.weight.dtype)        #\n",
    "            spk2, mem2 = self.lif2(self.fc2(spk1), mem2)\n",
    "            out.append(spk2)\n",
    "        return torch.stack(out)                                # [T,B,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd6624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.Compose([transforms.ToTensor()])\n",
    "train_ds = torchvision.datasets.MNIST(\"data\", True , download=True, transform=tr)\n",
    "test_ds  = torchvision.datasets.MNIST(\"data\", False, download=True, transform=tr)\n",
    "train_ld = DataLoader(train_ds, bs, True , num_workers=2, pin_memory=True)\n",
    "test_ld  = DataLoader(test_ds , bs, False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff8cf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SNN().to(device)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa76cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de613b",
   "metadata": {},
   "source": [
    "**train phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0468a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_ld,epochs):\n",
    "    for ep in range(1, epochs + 1):\n",
    "        net.train()\n",
    "        for imgs, lbls in tqdm(train_ld, desc=f\"train {ep}/{epochs}\"):\n",
    "            imgs = imgs.to(device).view(imgs.size(0), -1) \n",
    "            lbls = lbls.to(device)\n",
    "            spk  = spikegen.rate(imgs, T).to(device)\n",
    "            loss = loss_fn(net(spk).sum(0), lbls)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0376ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(net,train_ld,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae666a1",
   "metadata": {},
   "source": [
    "**test phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f888115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,loader):\n",
    "    @torch.no_grad()\n",
    "    def evaluate(model, loader, dtype):\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = (imgs.to(device).view(imgs.size(0), -1) ).to(dtype)\n",
    "            spk  = spikegen.rate(imgs, T).to(dtype).to(device)\n",
    "            preds = model(spk).sum(0).argmax(1)\n",
    "            correct += (preds == lbls.to(device)).sum().item()\n",
    "            total   += lbls.size(0)\n",
    "        return 100 * correct / total\n",
    "\n",
    "\n",
    "    acc32 = evaluate(net, test_ld, torch.float32)\n",
    "\n",
    "\n",
    "    net_fp16 = SNN().to(device)\n",
    "    net_fp16.load_state_dict(net.state_dict())\n",
    "    net_fp16.half().eval()\n",
    "    acc16 = evaluate(net_fp16, test_ld, torch.float16)\n",
    "\n",
    "    print(f\"Accuracy FP32 : {acc32:.2f}%\")\n",
    "    print(f\"Accuracy FP16 : {acc16:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97f596",
   "metadata": {},
   "source": [
    "create a test data spike train for cpp program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bdb7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imgs, lbls = next(iter(test_ld))\n",
    "\n",
    "# # img = imgs[9].to(device)\n",
    "# # label = lbls[9].item()\n",
    "\n",
    "# # img_flat = img.view(-1)\n",
    "\n",
    "\n",
    "# # spk = spikegen.rate(img_flat.unsqueeze(0), T).squeeze(1) \n",
    "\n",
    "# # print(\"Label:\", label)\n",
    "# # print(\"Spike array shape:\", spk.shape)  # [T, 784]\n",
    "# # print(\"Spike array (as int):\")\n",
    "# # print(spk.int())\n",
    "\n",
    "# spk_t = spk.int().cpu().tolist()  \n",
    "\n",
    "# with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\QNN\\\\HW\\\\FP32\\\\spikes.cpp\", \"w\") as f:\n",
    "#     f.write(\"#include <vector>\\n\")\n",
    "#     f.write(\"#include \\\"spikes.h\\\"\\n\")\n",
    "#     f.write(f\"int label = {label};\\n\")\n",
    "#     f.write(\"std::vector<std::vector<int>> spike_input = {\\n\")\n",
    "    \n",
    "#     for i, row in enumerate(spk_t): \n",
    "#         row_str = \", \".join(str(x) for x in row)\n",
    "#         comma = \",\" if i < len(spk_t) - 1 else \"\"\n",
    "#         f.write(f\"    {{{row_str}}}{comma}\\n\")\n",
    "#     f.write(\"};\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bcb16",
   "metadata": {},
   "source": [
    "create dataset for test with cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "416e0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = 1000  \n",
    "\n",
    "# all_spikes = []\n",
    "# all_labels = []\n",
    "\n",
    "# for batch_imgs, batch_lbls in test_ld:\n",
    "#     for i in range(len(batch_imgs)):\n",
    "#         if len(all_labels) >= num_samples:\n",
    "#             break\n",
    "\n",
    "#         img = batch_imgs[i].to(device)\n",
    "#         label = batch_lbls[i].item()\n",
    "#         img_flat = img.view(-1)\n",
    "\n",
    "#         spk = spikegen.rate(img_flat.unsqueeze(0), T).squeeze(1)  \n",
    "#         spk_np = spk.int().cpu().tolist()  \n",
    "\n",
    "#         all_spikes.append(spk_np)         \n",
    "#         all_labels.append(label)          \n",
    "\n",
    "#     if len(all_labels) >= num_samples:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6c55fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#     # with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\QNN\\\\HW\\\\FP32\\\\TestDataset.cpp\", \"w\") as f:\n",
    "# #     f.write(\"#include <vector>\\n\")\n",
    "# #     f.write(\"#include \\\"TestDataset.h\\\"\\n\")\n",
    "# #     f.write(\"std::vector<int> labels = {\\n\")\n",
    "# #     f.write(\"    \" + \", \".join(str(lbl) for lbl in all_labels) + \"\\n};\\n\\n\")\n",
    "\n",
    "# #     f.write(\"std::vector<std::vector<std::vector<int>>> dataset_spikes = {\\n\")\n",
    "# #     for i, sample in enumerate(all_spikes):\n",
    "# #         f.write(\"    {\\n\")\n",
    "# #         for j, timestep in enumerate(sample):\n",
    "# #             row_str = \", \".join(str(x) for x in timestep)\n",
    "# #             comma = \",\" if j < len(sample) - 1 else \"\"\n",
    "# #             f.write(f\"        {{{row_str}}}{comma}\\n\")\n",
    "# #         comma_sample = \",\" if i < len(all_spikes) - 1 else \"\"\n",
    "# #         f.write(f\"    }}{comma_sample}\\n\")\n",
    "# #     f.write(\"};\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362fbda",
   "metadata": {},
   "source": [
    "datatest with txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f518519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 100\n",
    "\n",
    "all_labels = []\n",
    "label_file = open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\HW\\\\FP32\\\\labels.txt\", \"w\")\n",
    "spike_file = open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\HW\\\\FP32\\\\spikes.txt\", \"w\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for batch_imgs, batch_lbls in test_ld:\n",
    "        for i in range(len(batch_imgs)):\n",
    "            if count >= num_samples:\n",
    "                break\n",
    "\n",
    "            img = batch_imgs[i].to(device)\n",
    "            label = batch_lbls[i].item()\n",
    "\n",
    "            img_flat = img.view(-1)\n",
    "            spk = spikegen.rate(img_flat.unsqueeze(0), T).squeeze(1)  # [T, 784]\n",
    "            spk_int = spk.int().cpu().tolist()\n",
    "\n",
    "            spike_file.write(f\"# sample {count}\\n\")\n",
    "            for timestep in spk_int:\n",
    "                line = \" \".join(str(x) for x in timestep)\n",
    "                spike_file.write(line + \"\\n\")\n",
    "\n",
    "            label_file.write(f\"{label}\\n\")\n",
    "\n",
    "            count += 1\n",
    "        if count >= num_samples:\n",
    "            break\n",
    "\n",
    "spike_file.close()\n",
    "label_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b540b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('model_weights.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "873a3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy FP32 : 96.28%\n",
      "Accuracy FP16 : 96.32%\n"
     ]
    }
   ],
   "source": [
    "test(net,test_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b9e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(),'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444277c7",
   "metadata": {},
   "source": [
    "Write weights with format cpp in weights.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591156b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.eval()\n",
    "# with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\QNN\\\\HW\\\\FP32\\\\weights.cpp\", \"w\") as cpp_file:\n",
    "#     cpp_file.write(\"#include <vector>\\n\\n\")\n",
    "#     cpp_file.write(\"#include \\\"weights.h\\\"\\n\")\n",
    "\n",
    "#     for name, param in net.state_dict().items():\n",
    "#         cpp_name = name.replace(\".\", \"_\")\n",
    "#         data = param.cpu().numpy()\n",
    "#         shape = data.shape\n",
    "\n",
    "#         cpp_file.write(f\"// shape: {shape}\\n\")\n",
    "#         cpp_file.write(f\"std::vector<float> {cpp_name} = {{\\n    \")\n",
    "#         cpp_file.write(\", \".join(f\"{v:.6f}\" for v in data.flatten()))\n",
    "#         cpp_file.write(\"\\n};\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
